{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa450d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen25/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "import my_prompt5_MA as my_prompt\n",
    "from file_managing import (\n",
    "    load_selected_samples,\n",
    "    get_actual_path,\n",
    "    get_gt_path,\n",
    ")\n",
    "from config import AGD20K_PATH, model_name\n",
    "from VLM_model_dot import QwenVLModel, MetricsTracker\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"PYTORCH_ENABLE_SDPA\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05cba076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: cuda\n",
      "ü§ñ Qwen/Qwen2.5-VL-3B-Instruct Î™®Îç∏ Î°úÎî©Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Î™®Îç∏ Î°úÎî© ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "missing_gt = 0\n",
    "model = QwenVLModel(model_name = model_name)\n",
    "metrics_tracker_ego = MetricsTracker(name=\"only_ego\")\n",
    "metrics_tracker_exo_best = MetricsTracker(name=\"with_exo_best\")\n",
    "\n",
    "json_path = os.path.join(\"selected_samples.json\")\n",
    "data = load_selected_samples(json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ba725e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 123 samples...\n",
      "==================================================\n",
      "--- Start   --------------------------------------------------------------------------------\n",
      "jump, skis\n"
     ]
    }
   ],
   "source": [
    "# Get total number of samples\n",
    "total_samples = len(data['selected_samples'])\n",
    "\n",
    "# Process each sample\n",
    "print(f\"Processing {total_samples} samples...\")\n",
    "print(\"=\" * 50)    \n",
    "for pair_key, sample_info in data[\"selected_samples\"].items():\n",
    "    print(\"--- Start  \", \"-\"*80) \n",
    "    \n",
    "    action = sample_info[\"action\"]\n",
    "    object_name = sample_info[\"object\"]\n",
    "    break\n",
    "print(f\"{action}, {object_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bebd237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : jump, Object : skis image_name : skis_002829.jpg\n"
     ]
    }
   ],
   "source": [
    "image_path = get_actual_path(sample_info[\"image_path\"])\n",
    "gt_path = get_gt_path(image_path)    \n",
    "print(f\"Action : {action}, Object : {object_name} image_name : {image_path.split('/')[-1]}\")\n",
    "exo_best_path = \"dogs.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37f84bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # MISSION: GENERATOR AGENT\\n\\nYou are the **Generator Agent**. Your task is to analyze the provided images (egocentric) and the task description. Generate a **dense cloud of all plausible keypoints** in the **egocentric image** where the action could occur. Be exhaustive and do not filter or judge the points yet.\\n\\n---\\n\\n## INPUTS\\n\\n* **Egocentric Image:** [Primary image for annotation]\\n* **Task:** Perform the action \\'jump\\' on the \\'skis\\'.\\n\\n---\\n\\n## OUTPUT FORMAT (Strict JSON)\\n\\nProvide your answer inside a single JSON block with the key \"generated_points\".\\n\\n```json\\n{\\n  \"generated_points\": [\\n    [x1, y1],\\n    [x2, y2],\\n    [x3, y3]\\n  ]\\n}```\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1 = my_prompt.step1(action, object_name)\n",
    "prompt1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184fbfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen ego Results!! : ```json\n",
      "{\n",
      "  \"generated_points\": [\n",
      "    [105, 1468],\n",
      "    [190, 1468],\n",
      "    [275, 1468],\n",
      "    [360, 1468],\n",
      "    [445, 1468]\n",
      "  ]\n",
      "}\n",
      "```\n",
      "parsed dots!!! : [[105, 1468], [190, 1468], [275, 1468], [360, 1468], [445, 1468]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text_result': '```json\\n{\\n  \"generated_points\": [\\n    [105, 1468],\\n    [190, 1468],\\n    [275, 1468],\\n    [360, 1468],\\n    [445, 1468]\\n  ]\\n}\\n```',\n",
       " 'dots': [[105, 1468], [190, 1468], [275, 1468], [360, 1468], [445, 1468]],\n",
       " 'dot_image_path': '/home/bongo/porter_notebook/research/new_qwen_AG/dot_images/only_ego/skis_002829_jump.jpg',\n",
       " 'dot_only_image_path': '/home/bongo/porter_notebook/research/new_qwen_AG/dot_images/dots_only/skis_002829_jump_dots.jpg',\n",
       " 'heatmap_image_path': '/home/bongo/porter_notebook/research/new_qwen_AG/dot_images/heatmaps/skis_002829_jump_heatmap.jpg',\n",
       " 'heatmap_tensor': tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.2444, 0.2478, 0.2512,  ..., 0.2185, 0.2153, 0.2122],\n",
       "         [0.2437, 0.2470, 0.2504,  ..., 0.2178, 0.2146, 0.2115],\n",
       "         [0.2429, 0.2462, 0.2496,  ..., 0.2170, 0.2139, 0.2108]]),\n",
       " 'metrics': {'KLD': 11.511372566223145,\n",
       "  'SIM': 6.163908272682761e-10,\n",
       "  'NSS': -0.3670256435871124}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.process_image_ego(image_path, prompt1, gt_path, action)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a2b901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# MISSION: INTERACTION PLANNER AGENT\\n\\nYou are the **Interaction Planner Agent**. Your task is to analyze the user\\'s intended **Task** to determine the optimal **Affordance Topology**. The topology describes the geometric \\'shape\\' of the interaction.\\n\\n---\\n\\n## INPUTS\\n\\n* **Task:** Perform the action \\'jump\\' on the \\'skis\\'.\\n\\n---\\n\\n## INSTRUCTIONS\\n\\n1.  **Reasoning:** First, briefly explain your reasoning. What is the physical goal of the action \\'jump\\'? Does it require precise force (`POINT`), interaction along an edge (`LINE/CURVE`), or convenience across an area (`REGION`)?\\n2.  **Decision:** Then, choose one of the three topology types.\\n\\n---\\n\\n## OUTPUT FORMAT (Strict JSON)\\n\\nProvide your answer inside a single JSON block with the key \"topology_analysis\".\\n\\n```json\\n{\\n  \"topology_analysis\": {\\n    \"rationale\": \"The action \\'open refrigerator\\' prioritizes convenience, allowing the user to pull from anywhere on the handle. Therefore, the interaction space is a functionally equivalent area.\",\\n    \"topology\": \"REGION\"\\n  }\\n}\\n\\n    '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2 = my_prompt.step2(action, object_name)\n",
    "prompt2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e240647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"topology_analysis\": {\\n    \"rationale\": \"The action \\'jump\\' on skis typically involves a combination of force and movement over a specific area. This requires precision in force application and movement along a path, which aligns more closely with the \\'POINT\\' topology where the action is performed at a specific location.\",\\n    \"topology\": \"POINT\"\\n  }\\n}\\n```'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = model.ask(prompt2)\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d6b190a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# MISSION: REFINER AGENT\\n\\nYou are the **Refiner Agent**. Your task is to take the dense point cloud from the Generator and the strategic topology decision from the Planner to produce the final, precise set of keypoints.\\n\\n---\\n\\n## INPUTS\\n\\n* **Generated Points:** A list of all plausible keypoints, e.g., `[[x1, y1], [x2, y2], ...]`\\n* **Topology Analysis:** The decision from the planner, e.g., `{ \"topology\": \"REGION\", \"rationale\": \"...\" }`\\n\\n---\\n\\n## INSTRUCTIONS\\n\\nApply the topology decision to filter the generated points using the following logic:\\n\\n* **If `topology` is `POINT`:** Select the **single most optimal point** from the candidates that best achieves the action\\'s goal.\\n* **If `topology` is `LINE/CURVE`:** Select the subset of points that form the most relevant **continuous line or curve**. Discard outliers.\\n* **If `topology` is `REGION`:** Select **all points** that fall within the primary functional area. Discard any stray points outside this main cluster.\\n\\n---\\n\\n## OUTPUT FORMAT (Strict JSON)\\n\\nProvide your final answer inside a single JSON block with the key \"final_keypoints\". The output should only contain the list of coordinates.\\n\\n```json\\n{\\n  \"final_keypoints\": [\\n    [x_final_1, y_final_1],\\n    [x_final_2, y_final_2]\\n  ]\\n}\\n```\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt3 = my_prompt.step3(action, object_name)\n",
    "prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f112e096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exo file name : dogs.jpg / exo_path\n",
      "final points :[[105, 1468], [110, 1470], [115, 1472], [120, 1474], [125, 1476], [130, 1478], [135, 1480], [140, 1482], [145, 1484], [150, 1486], [155, 1488], [160, 1490], [165, 1492], [170, 1494], [175, 1496], [180, 1498], [185, 1500], [190, 1502], [195, 1504], [200, 1506], [205, 1508], [210, 1510], [215, 1512], [220, 1514], [225, 1516], [230, 1518], [235, 1520], [240, 1522], [245, 1524], [250, 1526], [255, 1528], [260, 1530], [265, 1532], [270, 1534], [275, 1536], [280, 1538], [285, 1540], [290, 1542], [295, 1544], [300, 1546], [305, 1548], [310, 1550], [315, 1552], [320, 1554], [325, 1556], [330, 1558], [335, 1560], [340, 1562], [345, 1564], [350, 1566], [355, 1568], [360, 1570], [365, 1572], [370, 1574], [375, 1576], [380, 1578], [385, 1580], [390, 1582], [395, 1584], [400, 1586], [405, 1588], [410, 1590], [415, 1592], [420, 1594], [425, 1596], [430, 1598], [435, 1599], [440, 1601], [445, 1603], [450, 1605], [455, 1607], [460, 1609], [465, 1611], [470, 1613], [475, 1615], [480, 1617], [485, 1619], [490, 1621], [495, 1623], [500, 1625], [505, 1627], [510, 1629], [515, 1631], [520, 1633]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text_result': '```json\\n{\\n  \"generated_points\": [\\n    [105, 1468],\\n    [110, 1470],\\n    [115, 1472],\\n    [120, 1474],\\n    [125, 1476],\\n    [130, 1478],\\n    [135, 1480],\\n    [140, 1482],\\n    [145, 1484],\\n    [150, 1486],\\n    [155, 1488],\\n    [160, 1490],\\n    [165, 1492],\\n    [170, 1494],\\n    [175, 1496],\\n    [180, 1498],\\n    [185, 1500],\\n    [190, 1502],\\n    [195, 1504],\\n    [200, 1506],\\n    [205, 1508],\\n    [210, 1510],\\n    [215, 1512],\\n    [220, 1514],\\n    [225, 1516],\\n    [230, 1518],\\n    [235, 1520],\\n    [240, 1522],\\n    [245, 1524],\\n    [250, 1526],\\n    [255, 1528],\\n    [260, 1530],\\n    [265, 1532],\\n    [270, 1534],\\n    [275, 1536],\\n    [280, 1538],\\n    [285, 1540],\\n    [290, 1542],\\n    [295, 1544],\\n    [300, 1546],\\n    [305, 1548],\\n    [310, 1550],\\n    [315, 1552],\\n    [320, 1554],\\n    [325, 1556],\\n    [330, 1558],\\n    [335, 1560],\\n    [340, 1562],\\n    [345, 1564],\\n    [350, 1566],\\n    [355, 1568],\\n    [360, 1570],\\n    [365, 1572],\\n    [370, 1574],\\n    [375, 1576],\\n    [380, 1578],\\n    [385, 1580],\\n    [390, 1582],\\n    [395, 1584],\\n    [400, 1586],\\n    [405, 1588],\\n    [410, 1590],\\n    [415, 1592],\\n    [420, 1594],\\n    [425, 1596],\\n    [430, 1598],\\n    [435, 1599],\\n    [440, 1601],\\n    [445, 1603],\\n    [450, 1605],\\n    [455, 1607],\\n    [460, 1609],\\n    [465, 1611],\\n    [470, 1613],\\n    [475, 1615],\\n    [480, 1617],\\n    [485, 1619],\\n    [490, 1621],\\n    [495, 1623],\\n    [500, 1625],\\n    [505, 1627],\\n    [510, 1629],\\n    [515, 1631],\\n    [520, 1633],\\n    [525,',\n",
       " 'dots': [[105, 1468],\n",
       "  [110, 1470],\n",
       "  [115, 1472],\n",
       "  [120, 1474],\n",
       "  [125, 1476],\n",
       "  [130, 1478],\n",
       "  [135, 1480],\n",
       "  [140, 1482],\n",
       "  [145, 1484],\n",
       "  [150, 1486],\n",
       "  [155, 1488],\n",
       "  [160, 1490],\n",
       "  [165, 1492],\n",
       "  [170, 1494],\n",
       "  [175, 1496],\n",
       "  [180, 1498],\n",
       "  [185, 1500],\n",
       "  [190, 1502],\n",
       "  [195, 1504],\n",
       "  [200, 1506],\n",
       "  [205, 1508],\n",
       "  [210, 1510],\n",
       "  [215, 1512],\n",
       "  [220, 1514],\n",
       "  [225, 1516],\n",
       "  [230, 1518],\n",
       "  [235, 1520],\n",
       "  [240, 1522],\n",
       "  [245, 1524],\n",
       "  [250, 1526],\n",
       "  [255, 1528],\n",
       "  [260, 1530],\n",
       "  [265, 1532],\n",
       "  [270, 1534],\n",
       "  [275, 1536],\n",
       "  [280, 1538],\n",
       "  [285, 1540],\n",
       "  [290, 1542],\n",
       "  [295, 1544],\n",
       "  [300, 1546],\n",
       "  [305, 1548],\n",
       "  [310, 1550],\n",
       "  [315, 1552],\n",
       "  [320, 1554],\n",
       "  [325, 1556],\n",
       "  [330, 1558],\n",
       "  [335, 1560],\n",
       "  [340, 1562],\n",
       "  [345, 1564],\n",
       "  [350, 1566],\n",
       "  [355, 1568],\n",
       "  [360, 1570],\n",
       "  [365, 1572],\n",
       "  [370, 1574],\n",
       "  [375, 1576],\n",
       "  [380, 1578],\n",
       "  [385, 1580],\n",
       "  [390, 1582],\n",
       "  [395, 1584],\n",
       "  [400, 1586],\n",
       "  [405, 1588],\n",
       "  [410, 1590],\n",
       "  [415, 1592],\n",
       "  [420, 1594],\n",
       "  [425, 1596],\n",
       "  [430, 1598],\n",
       "  [435, 1599],\n",
       "  [440, 1601],\n",
       "  [445, 1603],\n",
       "  [450, 1605],\n",
       "  [455, 1607],\n",
       "  [460, 1609],\n",
       "  [465, 1611],\n",
       "  [470, 1613],\n",
       "  [475, 1615],\n",
       "  [480, 1617],\n",
       "  [485, 1619],\n",
       "  [490, 1621],\n",
       "  [495, 1623],\n",
       "  [500, 1625],\n",
       "  [505, 1627],\n",
       "  [510, 1629],\n",
       "  [515, 1631],\n",
       "  [520, 1633]],\n",
       " 'dot_image_path': '/home/bongo/porter_notebook/research/new_qwen_AG/dot_images/with_exo/skis_002829_jump_exo_dogs.jpg',\n",
       " 'dot_only_image_path': '/home/bongo/porter_notebook/research/new_qwen_AG/dot_images/dots_only/skis_002829_jump_dots_exo.jpg',\n",
       " 'heatmap_image_path': '/home/bongo/porter_notebook/research/new_qwen_AG/dot_images/heatmaps/skis_002829_jump_heatmap_exo_reference_dogs.jpg',\n",
       " 'heatmap_tensor': tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1448, 0.1472, 0.1496,  ..., 0.3665, 0.3625, 0.3585],\n",
       "         [0.1446, 0.1470, 0.1494,  ..., 0.3666, 0.3626, 0.3586],\n",
       "         [0.1444, 0.1468, 0.1492,  ..., 0.3666, 0.3626, 0.3586]]),\n",
       " 'metrics': {'KLD': 11.511373519897461,\n",
       "  'SIM': 1.3814098476228054e-10,\n",
       "  'NSS': -0.33930423855781555}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = model.process_image_exo(image_path, prompt, gt_path, exo_best_path, action)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
