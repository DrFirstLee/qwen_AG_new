{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccef783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/qwen25/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "import my_prompt5 as my_prompt\n",
    "from file_managing import (\n",
    "    load_selected_samples,\n",
    "    get_actual_path,\n",
    "    get_gt_path,\n",
    ")\n",
    "from config import AGD20K_PATH, model_name\n",
    "from VLM_model_dot import QwenVLModel, MetricsTracker\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"PYTORCH_ENABLE_SDPA\"] = \"1\"\n",
    "\n",
    "missing_gt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3338eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def affordance_grounding(model, action, object_name, image_path, gt_path, exo_path=None,  failed_heatmap_path=None, validation_reason=None):\n",
    "    \"\"\"\n",
    "    Process each image using Qwen VL model\n",
    "    \"\"\"\n",
    "    print(f\"Processing image: Action: {action}, Object: {object_name}, Image path: {image_path}, GT path: {gt_path}, Image exists: {os.path.exists(image_path)}, GT exists: {os.path.exists(gt_path)}\")\n",
    "    \n",
    "\n",
    "    if exo_path is None:\n",
    "        prompt = my_prompt.process_image_ego_prompt(action, object_name)\n",
    "               \n",
    "        results = model.process_image_ego(image_path, prompt, gt_path, action)\n",
    "\n",
    "        \n",
    "    else:\n",
    "\n",
    "        prompt = my_prompt.process_image_exo_prompt(action, object_name)\n",
    "        results = model.process_image_exo(image_path, prompt, gt_path, exo_path, action)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8778ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: cuda\n",
      "ü§ñ Qwen/Qwen2.5-VL-32B-Instruct Î™®Îç∏ Î°úÎî©Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:08<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Î™®Îç∏ Î°úÎî© ÏôÑÎ£å!\n",
      "Processing 123 samples...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "    # Initialize Qwen VL model\n",
    "    model = QwenVLModel(model_name = model_name)\n",
    "    metrics_tracker_ego = MetricsTracker(name=\"only_ego\")\n",
    "    metrics_tracker_exo_best = MetricsTracker(name=\"with_exo_best\")\n",
    "\n",
    "    json_path = os.path.join(\"selected_samples.json\")\n",
    "    data = load_selected_samples(json_path)\n",
    "\n",
    "    # Get total number of samples\n",
    "    total_samples = len(data['selected_samples'])\n",
    "    \n",
    "    # Process each sample\n",
    "    print(f\"Processing {total_samples} samples...\")\n",
    "    print(\"=\" * 50)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62d87523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump_skis {'action': 'jump', 'object': 'skis', 'image_path': '${AGD20K_PATH}/Seen/testset/egocentric/jump/skis/skis_002829.jpg'}\n"
     ]
    }
   ],
   "source": [
    "for pair_key, sample_info in data[\"selected_samples\"].items():\n",
    "    if( sample_info['object'] =='skis') and (  sample_info['action'] =='jump'):\n",
    "        print(pair_key, sample_info )\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db024ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n        You are given an image showing a 'skis' involved in the action 'jump'.\\n\\n        üéØ Your task:\\n        Identify several **precise keypoints** in the image that are essential for performing the action 'jump' on the object 'skis'.\\n        and rating the importance of that point\\n\\n        ‚ö†Ô∏è Important Instructions:\\n        - Only return **single-point** coordinates and prediction score in the format [x, y, prediction_score]\\n        - Do **not** return bounding boxes or regions\\n        - All points must lie **within** the 'skis'\\n        - Avoid placing multiple points too close together\\n        - If there are more than one 'skis', give me point from each 'skis'\\n        - ‚ùå Do **not** include any text, comments, or labels\\n\\n        ‚úÖ Output format (strict):\\n        [\\n        [x1, y1,prediction_score],\\n        [x2, y2,prediction_score],\\n        [x3, y3,prediction_score]\\n        ]\\n        \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = sample_info[\"action\"]\n",
    "object_name = sample_info[\"object\"]\n",
    "my_prompt.process_image_ego_prompt_w_pred(action, object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87096e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : jump, Object : skis image_name : skis_002829.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen ego Results!! : [\n",
      "    [150, 700, 0.8],  // Midpoint of the left ski, important for balance during the jump.\n",
      "    [400, 700, 0.8],  // Midpoint of the right ski, important for balance during the jump.\n",
      "    [150, 100, 0.6],  // Tip of the left ski, crucial for initiating the jump.\n",
      "    [400, 100, 0.6],  // Tip of the right ski, crucial for initiating the jump.\n",
      "    [150, 1300, 0.5], // Tail of the left ski, important for control and landing.\n",
      "    [400, 1300, 0.5]  // Tail of the right ski, important for control and landing.\n",
      "]\n",
      "final points :[[150, 700], [400, 700], [150, 100], [400, 100], [150, 1300], [400, 1300]]\n",
      "parsed dots!!! : [[150, 700], [400, 700], [150, 100], [400, 100], [150, 1300], [400, 1300]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text_result': '[\\n    [150, 700, 0.8],  // Midpoint of the left ski, important for balance during the jump.\\n    [400, 700, 0.8],  // Midpoint of the right ski, important for balance during the jump.\\n    [150, 100, 0.6],  // Tip of the left ski, crucial for initiating the jump.\\n    [400, 100, 0.6],  // Tip of the right ski, crucial for initiating the jump.\\n    [150, 1300, 0.5], // Tail of the left ski, important for control and landing.\\n    [400, 1300, 0.5]  // Tail of the right ski, important for control and landing.\\n]',\n",
       " 'dots': [[150, 700],\n",
       "  [400, 700],\n",
       "  [150, 100],\n",
       "  [400, 100],\n",
       "  [150, 1300],\n",
       "  [400, 1300]],\n",
       " 'dot_image_path': '/root/qwen_AG_new/dot_images/only_ego/skis_002829_jump.jpg',\n",
       " 'dot_only_image_path': '/root/qwen_AG_new/dot_images/dots_only/skis_002829_jump_dots.jpg',\n",
       " 'heatmap_image_path': '/root/qwen_AG_new/dot_images/heatmaps/skis_002829_jump_heatmap.jpg',\n",
       " 'heatmap_tensor': tensor([[0.1622, 0.1649, 0.1676,  ..., 0.1414, 0.1389, 0.1365],\n",
       "         [0.1640, 0.1667, 0.1695,  ..., 0.1430, 0.1405, 0.1380],\n",
       "         [0.1658, 0.1685, 0.1713,  ..., 0.1446, 0.1420, 0.1395],\n",
       "         ...,\n",
       "         [0.0311, 0.0317, 0.0322,  ..., 0.0267, 0.0262, 0.0257],\n",
       "         [0.0304, 0.0309, 0.0315,  ..., 0.0261, 0.0256, 0.0251],\n",
       "         [0.0296, 0.0302, 0.0307,  ..., 0.0255, 0.0250, 0.0245]]),\n",
       " 'metrics': {'KLD': 1.3854244947433472,\n",
       "  'SIM': 0.29591378569602966,\n",
       "  'NSS': 1.2132643461227417}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "action = sample_info[\"action\"]\n",
    "object_name = sample_info[\"object\"]\n",
    "\n",
    "image_path = get_actual_path(sample_info[\"image_path\"])\n",
    "gt_path = get_gt_path(image_path)    \n",
    "print(f\"Action : {action}, Object : {object_name} image_name : {image_path.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "# Process the image\n",
    "prompt = my_prompt.process_image_ego_prompt_w_pred(action, object_name)\n",
    "        \n",
    "results = model.process_image_ego(image_path, prompt, gt_path, action)\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "63ef9c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : jump, Object : skis image_name : skis_002829.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    You are given two images:\\n    1. An **egocentric** image where you must select keypoints.\\n    2. An **exocentric** reference image showing how the action 'jump' is typically performed on the 'skis'.\\n\\n    üéØ Task:\\n    Select multiple [x, y] keypoints in the **egocentric image** that are critical for performing the action 'jump' on the 'skis'.\\n\\n    üîç Use the exocentric image to:\\n    - Understand typical interaction patterns\\n    - Identify functionally important parts (e.g., contact or force areas)\\n\\n    üìå Guidelines:\\n    - Keypoints must lie **within** the 'skis' in the egocentric image\\n    - If there are multiple 'skis' instances, mark keypoints on **each of them**\\n    - Place **at least 3 well-separated** points covering the entire functional region\\n    - e.g., for a handle: both ends and the center\\n    - Avoid clustering or irrelevant placements\\n\\n    ‚õî Do NOT:\\n    - Include text, labels, bounding boxes, or extra formatting\\n\\n    ‚úÖ Output format (strict):\\n    [\\n    [x1, y1],\\n    [x2, y2],\\n    [x3, y3]\\n    ]\\n    \""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "action = sample_info[\"action\"]\n",
    "object_name = sample_info[\"object\"]\n",
    "\n",
    "image_path = get_actual_path(sample_info[\"image_path\"])\n",
    "gt_path = get_gt_path(image_path)    \n",
    "print(f\"Action : {action}, Object : {object_name} image_name : {image_path.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "# Process the image\n",
    "prompt = my_prompt.process_image_exo_prompt(action, object_name)\n",
    "prompt    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de2659f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exo file name : jump_skis_004492.jpg / exo_path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final points :[[140, 1060], [180, 1060], [375, 1060], [415, 1060]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text_result': 'To perform the action \"jump\" on skis, the key functional regions on the skis are typically near the bindings, which secure the boots and allow for control during jumps. Based on the provided images:\\n\\n- The **egocentric image** shows a pair of skis with visible bindings near the middle section.\\n- The **exocentric image** demonstrates people skiing, indicating that the bindings are crucial for jumping.\\n\\nHere are the selected keypoints on the skis from the egocentric image:\\n\\n```json\\n[\\n    [140, 1060],  // Near the binding area on the left ski\\n    [180, 1060],  // Near the binding area on the left ski\\n    [375, 1060],  // Near the binding area on the right ski\\n    [415, 1060]   // Near the binding area on the right ski\\n]\\n```\\n\\nThese points are strategically placed near the bindings, which are essential for securing the boots and providing control during a jump. They are well-separated and cover the functional region effectively.',\n",
       " 'dots': [[140, 1060], [180, 1060], [375, 1060], [415, 1060]],\n",
       " 'dot_image_path': '/root/qwen_AG_new/dot_images/with_exo/skis_002829_jump_exo_jump_skis_004492.jpg',\n",
       " 'dot_only_image_path': '/root/qwen_AG_new/dot_images/dots_only/skis_002829_jump_dots_exo.jpg',\n",
       " 'heatmap_image_path': '/root/qwen_AG_new/dot_images/heatmaps/skis_002829_jump_heatmap_exo_reference_jump_skis_004492.jpg',\n",
       " 'heatmap_tensor': tensor([[6.7386e-29, 8.1299e-29, 9.5354e-29,  ..., 2.6517e-29, 1.3186e-29,\n",
       "          0.0000e+00],\n",
       "         [1.6857e-28, 1.8418e-28, 1.9995e-28,  ..., 1.2273e-28, 1.0777e-28,\n",
       "          9.2977e-29],\n",
       "         [2.8198e-28, 2.9948e-28, 3.1717e-28,  ..., 2.3055e-28, 2.1377e-28,\n",
       "          1.9718e-28],\n",
       "         ...,\n",
       "         [7.8344e-06, 7.9656e-06, 8.0982e-06,  ..., 7.4489e-06, 7.3231e-06,\n",
       "          7.1987e-06],\n",
       "         [7.4711e-06, 7.5963e-06, 7.7227e-06,  ..., 7.1035e-06, 6.9836e-06,\n",
       "          6.8650e-06],\n",
       "         [7.1240e-06, 7.2433e-06, 7.3639e-06,  ..., 6.7734e-06, 6.6591e-06,\n",
       "          6.5460e-06]]),\n",
       " 'metrics': {'KLD': 7.595706939697266,\n",
       "  'SIM': 0.014082727953791618,\n",
       "  'NSS': -0.49653252959251404}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exo_path = \"/root/AGD20K/Seen/trainset/exocentric/jump/skis/jump_skis_004492.jpg\"\n",
    "results = model.process_image_exo(image_path, prompt,gt_path, exo_path, action)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5303196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To perform the action \"jump\" on skis, the key functional regions on the skis are typically near the bindings, which secure the boots and allow for control during jumps. Based on the provided images:\n",
      "\n",
      "- The **egocentric image** shows a pair of skis with visible bindings near the middle section.\n",
      "- The **exocentric image** demonstrates people skiing, indicating that the bindings are crucial for jumping.\n",
      "\n",
      "Here are the selected keypoints on the skis from the egocentric image:\n",
      "\n",
      "```json\n",
      "[\n",
      "    [140, 1060],  // Near the binding area on the left ski\n",
      "    [180, 1060],  // Near the binding area on the left ski\n",
      "    [375, 1060],  // Near the binding area on the right ski\n",
      "    [415, 1060]   // Near the binding area on the right ski\n",
      "]\n",
      "```\n",
      "\n",
      "These points are strategically placed near the bindings, which are essential for securing the boots and providing control during a jump. They are well-separated and cover the functional region effectively.\n"
     ]
    }
   ],
   "source": [
    "print(results['text_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a52e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To determine the points of contact between a person and skis when jumping, we need to consider the typical anatomy of a ski and how a person interacts with it during a jump. The key areas of contact are usually:\\n\\n1. **The bindings**: These are the mechanisms that secure the boots to the skis. They are located near the center of the skis.\\n2. **The tips and tails of the skis**: While these areas are less likely to be in direct contact with the body, they can come into play if the skier lands awkwardly or if the skis are not properly aligned.\\n\\nGiven the coordinates provided, let's analyze them:\\n\\n- **[140, 1060]**: This is likely near the front binding area, where the toe of the boot is secured. This is a high-probability contact point.\\n- **[180, 1060]**: This is also near the binding area but slightly further back. It is still a high-probability contact point.\\n- **[375, 1060]**: This is closer to the tail of the ski, which is less likely to be in direct contact with the body during a jump.\\n- **[415, 1060]**: This is even closer to the tail, making it an even lower-probability contact point.\\n\\n### Score Assignment:\\n- **[140, 1060]**: High probability of contact (score: 9)\\n- **[180, 1060]**: High probability of contact (score: 8)\\n- **[375, 1060]**: Low probability of contact (score: 3)\\n- **[415, 1060]**: Very low probability of contact (score: 1)\\n\\n### Final Output:\\n```json\\n[\\n  [140, 1060, 9],\\n  [180, 1060, 8],\\n  [375, 1060, 3],\\n  [415, 1060, 1]\\n]\\n```\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = f'''\n",
    "\n",
    "When a person {action} on {object_name}, which parts of the {object_name} could be the points of contact with a human body?\n",
    "Please give me a score for each point. score from 0~10.\n",
    "if dots are incorrect, then say \"WRONG\"\n",
    "\n",
    "[\n",
    "    [140, 1060],  \n",
    "    [180, 1060],  \n",
    "    [375, 1060],  \n",
    "    [415, 1060]   \n",
    "]\n",
    "\n",
    "‚úÖ Output format (strict):\n",
    "[\n",
    "[x1, y1,prediction_score],\n",
    "[x2, y2,prediction_score],\n",
    "[x3, y3,prediction_score]\n",
    "]\n",
    "\n",
    "'''\n",
    "\n",
    "prediction_score = model.ask(question = question) \n",
    "prediction_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cbdbab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the points of contact between a person and skis when jumping, we need to consider the typical anatomy of a ski and how a person interacts with it during a jump. The key areas of contact are usually:\n",
      "\n",
      "1. **The bindings**: These are the mechanisms that secure the boots to the skis. They are located near the center of the skis.\n",
      "2. **The tips and tails of the skis**: While these areas are less likely to be in direct contact with the body, they can come into play if the skier lands awkwardly or if the skis are not properly aligned.\n",
      "\n",
      "Given the coordinates provided, let's analyze them:\n",
      "\n",
      "- **[140, 1060]**: This is likely near the front binding area, where the toe of the boot is secured. This is a high-probability contact point.\n",
      "- **[180, 1060]**: This is also near the binding area but slightly further back. It is still a high-probability contact point.\n",
      "- **[375, 1060]**: This is closer to the tail of the ski, which is less likely to be in direct contact with the body during a jump.\n",
      "- **[415, 1060]**: This is even closer to the tail, making it an even lower-probability contact point.\n",
      "\n",
      "### Score Assignment:\n",
      "- **[140, 1060]**: High probability of contact (score: 9)\n",
      "- **[180, 1060]**: High probability of contact (score: 8)\n",
      "- **[375, 1060]**: Low probability of contact (score: 3)\n",
      "- **[415, 1060]**: Very low probability of contact (score: 1)\n",
      "\n",
      "### Final Output:\n",
      "```json\n",
      "[\n",
      "  [140, 1060, 9],\n",
      "  [180, 1060, 8],\n",
      "  [375, 1060, 3],\n",
      "  [415, 1060, 1]\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(prediction_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ef0c780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/AGD20K/Seen/testset/egocentric/jump/skis/skis_002829.jpg'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = get_actual_path(sample_info[\"image_path\"])\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930d231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To determine the points of contact between a human body and skis when jumping, we need to consider the typical areas where a skier's body might touch the skis during such an action. Generally, these points would be near the bindings or the central area of the skis, as these are the regions where the boots are attached and the skier's weight is distributed.\\n\\n### Analysis of the Provided Points:\\n1. **[140, 1060]**: This point is located near the center of the ski, close to the bindings area. It is a plausible point of contact because this is where the skier's boots are typically attached, and it is a common area for pressure distribution.\\n2. **[180, 1060]**: This point is also near the center but slightly further toward the tail of the ski. While it is still within the central region, it is less likely to be a primary point of contact compared to the bindings area.\\n3. **[375, 1060]**: Similar to [140, 1060], this point is near the center of the other ski, close to the bindings area. It is another plausible point of contact.\\n4. **[415, 1060]**: Similar to [180, 1060], this point is near the center but slightly toward the tail. It is less likely to be a primary point of contact.\\n\\n### Scores:\\n- **[140, 1060]**: 8 (High likelihood due to being near the bindings)\\n- **[180, 1060]**: 5 (Moderate likelihood, but less central than [140, 1060])\\n- **[375, 1060]**: 8 (High likelihood due to being near the bindings)\\n- **[415, 1060]**: 5 (Moderate likelihood, but less central than [375, 1060])\\n\\n### Final Output:\\n```json\\n[\\n  [140, 1060, 8],\\n  [180, 1060, 5],\\n  [375, 1060, 8],\\n  [415, 1060, 5]\\n]\\n```\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = get_actual_path(sample_info[\"image_path\"])\n",
    "image_path\n",
    "\n",
    "question = f'''\n",
    "\n",
    "When a person {action} on {object_name}, which parts of the {object_name} could be the points of contact with a human body?\n",
    "Please give me a score for each point. score from 0~10.\n",
    "\n",
    "[\n",
    "    [140, 1060],  \n",
    "    [180, 1060],  \n",
    "    [375, 1060],  \n",
    "    [415, 1060]   \n",
    "]\n",
    "\n",
    "‚úÖ Output format (strict):\n",
    "[\n",
    "[x1, y1,prediction_score],\n",
    "[x2, y2,prediction_score],\n",
    "[x3, y3,prediction_score]\n",
    "]\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "prediction_score = model.ask_with_image(question = question, image_path = image_path) \n",
    "prediction_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the points of contact between a human body and skis when jumping, we need to consider the typical areas where a skier's body might touch the skis during such an action. Generally, these points would be near the bindings or the central area of the skis, as these are the regions where the boots are attached and the skier's weight is distributed.\n",
      "\n",
      "### Analysis of the Provided Points:\n",
      "1. **[140, 1060]**: This point is located near the center of the ski, close to the bindings area. It is a plausible point of contact because this is where the skier's boots are typically attached, and it is a common area for pressure distribution.\n",
      "2. **[180, 1060]**: This point is also near the center but slightly further toward the tail of the ski. While it is still within the central region, it is less likely to be a primary point of contact compared to the bindings area.\n",
      "3. **[375, 1060]**: Similar to [140, 1060], this point is near the center of the other ski, close to the bindings area. It is another plausible point of contact.\n",
      "4. **[415, 1060]**: Similar to [180, 1060], this point is near the center but slightly toward the tail. It is less likely to be a primary point of contact.\n",
      "\n",
      "### Scores:\n",
      "- **[140, 1060]**: 8 (High likelihood due to being near the bindings)\n",
      "- **[180, 1060]**: 5 (Moderate likelihood, but less central than [140, 1060])\n",
      "- **[375, 1060]**: 8 (High likelihood due to being near the bindings)\n",
      "- **[415, 1060]**: 5 (Moderate likelihood, but less central than [375, 1060])\n",
      "\n",
      "### Final Output:\n",
      "```json\n",
      "[\n",
      "  [140, 1060, 8],\n",
      "  [180, 1060, 5],\n",
      "  [375, 1060, 8],\n",
      "  [415, 1060, 5]\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(prediction_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To determine the points of contact between a human body and skis when jumping, we need to consider the typical posture and movement during a ski jump. Generally, the points of contact would be near the bindings, where the boots are attached to the skis. These areas are closer to the middle of the skis rather than the tips or tails.\\n\\n### Analysis of the Provided Points:\\n1. **[140, 150]**: This point is near the tip of the left ski. The tip is unlikely to be a primary point of contact during a jump.\\n2. **[150, 700]**: This point is near the middle of the left ski, close to where the bindings are typically located. This is a likely point of contact.\\n3. **[160, 1200]**: This point is near the tail of the left ski. The tail is also unlikely to be a primary point of contact.\\n4. **[380, 150]**: This point is near the tip of the right ski. Similar to the left ski, the tip is not a likely point of contact.\\n5. **[390, 700]**: This point is near the middle of the right ski, close to where the bindings are typically located. This is a likely point of contact.\\n6. **[400, 1200]**: This point is near the tail of the right ski. Like the left ski, the tail is not a likely point of contact.\\n\\n### Scores:\\n- Points near the bindings (middle of the skis) are most likely to be in contact with the human body during a jump. These are **[150, 700]** and **[390, 700]**.\\n- Points near the tips and tails (**[140, 150]**, **[160, 1200]**, **[380, 150]**, and **[400, 1200]**) are less likely to be in contact.\\n\\n### Final Scores:\\n- **[140, 150, 2]**: Tip of the left ski (low likelihood).\\n- **[150, 700, 8]**: Middle of the left ski (high likelihood).\\n- **[160, 1200, 2]**: Tail of the left ski (low likelihood).\\n- **[380, 150, 2]**: Tip of the right ski (low likelihood).\\n- **[390, 700, 8]**: Middle of the right ski (high likelihood).\\n- **[400, 1200, 2]**: Tail of the right ski (low likelihood).\\n\\n### Output:\\n```json\\n[\\n  [140, 150, 2],\\n  [150, 700, 8],\\n  [160, 1200, 2],\\n  [380, 150, 2],\\n  [390, 700, 8],\\n  [400, 1200, 2]\\n]\\n```'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = f'''\n",
    "\n",
    "When a person {action} on {object_name}, which parts of the {object_name} could be the points of contact with a human body?\n",
    "Please give me a score for each point. score from 0~10.\n",
    "\n",
    "[\n",
    "    [140, 150], \n",
    "    [150, 700], \n",
    "    [160, 1200],\n",
    "    [380, 150], \n",
    "    [390, 700], \n",
    "    [400, 1200] ,\n",
    "]\n",
    "\n",
    "‚úÖ Output format (strict):\n",
    "[\n",
    "[x1, y1,prediction_score],\n",
    "[x2, y2,prediction_score],\n",
    "[x3, y3,prediction_score]\n",
    "]\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "prediction_score = model.ask_with_image(question = question, image_path = image_path) \n",
    "prediction_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "724e8ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the points of contact between a human body and skis when jumping, we need to consider the typical posture and movement during a ski jump. Generally, the points of contact would be near the bindings, where the boots are attached to the skis. These areas are closer to the middle of the skis rather than the tips or tails.\n",
      "\n",
      "### Analysis of the Provided Points:\n",
      "1. **[140, 150]**: This point is near the tip of the left ski. The tip is unlikely to be a primary point of contact during a jump.\n",
      "2. **[150, 700]**: This point is near the middle of the left ski, close to where the bindings are typically located. This is a likely point of contact.\n",
      "3. **[160, 1200]**: This point is near the tail of the left ski. The tail is also unlikely to be a primary point of contact.\n",
      "4. **[380, 150]**: This point is near the tip of the right ski. Similar to the left ski, the tip is not a likely point of contact.\n",
      "5. **[390, 700]**: This point is near the middle of the right ski, close to where the bindings are typically located. This is a likely point of contact.\n",
      "6. **[400, 1200]**: This point is near the tail of the right ski. Like the left ski, the tail is not a likely point of contact.\n",
      "\n",
      "### Scores:\n",
      "- Points near the bindings (middle of the skis) are most likely to be in contact with the human body during a jump. These are **[150, 700]** and **[390, 700]**.\n",
      "- Points near the tips and tails (**[140, 150]**, **[160, 1200]**, **[380, 150]**, and **[400, 1200]**) are less likely to be in contact.\n",
      "\n",
      "### Final Scores:\n",
      "- **[140, 150, 2]**: Tip of the left ski (low likelihood).\n",
      "- **[150, 700, 8]**: Middle of the left ski (high likelihood).\n",
      "- **[160, 1200, 2]**: Tail of the left ski (low likelihood).\n",
      "- **[380, 150, 2]**: Tip of the right ski (low likelihood).\n",
      "- **[390, 700, 8]**: Middle of the right ski (high likelihood).\n",
      "- **[400, 1200, 2]**: Tail of the right ski (low likelihood).\n",
      "\n",
      "### Output:\n",
      "```json\n",
      "[\n",
      "  [140, 150, 2],\n",
      "  [150, 700, 8],\n",
      "  [160, 1200, 2],\n",
      "  [380, 150, 2],\n",
      "  [390, 700, 8],\n",
      "  [400, 1200, 2]\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(prediction_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the points of contact between a human body and skis during a jump, we need to consider the typical posture and movement of a skier. During a jump, the skier's body is often positioned in a way that minimizes air resistance and maximizes control. The skis are typically held parallel to the ground, and the skier's hands or feet may come into contact with the skis.\n",
      "\n",
      "### Analysis:\n",
      "1. **Front Section of the Left Ski ([140, 150]):**\n",
      "   - This area is near the tip of the ski. It is unlikely to be a primary point of contact because the skier's body is usually positioned further back for balance.\n",
      "   - **Score:** 2\n",
      "\n",
      "2. **Middle Section of the Left Ski ([150, 700]):**\n",
      "   - This area is closer to the center of the ski, where the skier's hands or feet might touch the ski for balance or control.\n",
      "   - **Score:** 7\n",
      "\n",
      "3. **Back Section of the Left Ski ([160, 1200]):**\n",
      "   - This area is near the tail of the ski. It is a common point of contact because the skier's hands or feet may rest here for stability during a jump.\n",
      "   - **Score:** 8\n",
      "\n",
      "4. **Front Section of the Right Ski ([380, 150]):**\n",
      "   - Similar to the front section of the left ski, this area is near the tip and is less likely to be a primary point of contact.\n",
      "   - **Score:** 2\n",
      "\n",
      "5. **Middle Section of the Right Ski ([390, 700]):**\n",
      "   - Like the middle section of the left ski, this area is a plausible point of contact for balance or control.\n",
      "   - **Score:** 7\n",
      "\n",
      "6. **Back Section of the Right Ski ([400, 1200]):**\n",
      "   - Similar to the back section of the left ski, this area is a common point of contact for stability.\n",
      "   - **Score:** 8\n",
      "\n",
      "### Final Output:\n",
      "```json\n",
      "[\n",
      "  [140, 150, 2],\n",
      "  [150, 700, 7],\n",
      "  [160, 1200, 8],\n",
      "  [380, 150, 2],\n",
      "  [390, 700, 7],\n",
      "  [400, 1200, 8]\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(prediction_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f3a042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "push_bicycle {'action': 'push', 'object': 'bicycle', 'image_path': '${AGD20K_PATH}/Seen/testset/egocentric/push/bicycle/bicycle_002432.jpg'}\n"
     ]
    }
   ],
   "source": [
    "for pair_key, sample_info in data[\"selected_samples\"].items():\n",
    "    if( sample_info['object'] =='bicycle') and (  sample_info['action'] =='push'):\n",
    "        print(pair_key, sample_info )\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6185da77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : push, Object : bicycle image_name : bicycle_002432.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen ego Results!! : [\n",
      "    [450, 308],  // Rear wheel contact point with ground\n",
      "    [196, 270],  // Frame near the center of gravity\n",
      "    [100, 220]   // Front wheel contact point with ground\n",
      "]\n",
      "final points :[[450, 308], [196, 270], [100, 220]]\n",
      "parsed dots!!! : [[450, 308], [196, 270], [100, 220]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text_result': '[\\n    [450, 308],  // Rear wheel contact point with ground\\n    [196, 270],  // Frame near the center of gravity\\n    [100, 220]   // Front wheel contact point with ground\\n]',\n",
       " 'dots': [[450, 308], [196, 270], [100, 220]],\n",
       " 'dot_image_path': '/root/qwen_AG_new/dot_images/only_ego/bicycle_002432_push.jpg',\n",
       " 'dot_only_image_path': '/root/qwen_AG_new/dot_images/dots_only/bicycle_002432_push_dots.jpg',\n",
       " 'heatmap_image_path': '/root/qwen_AG_new/dot_images/heatmaps/bicycle_002432_push_heatmap.jpg',\n",
       " 'heatmap_tensor': tensor([[4.6748e-06, 4.8726e-06, 5.0766e-06,  ..., 2.3473e-13, 1.1308e-13,\n",
       "          0.0000e+00],\n",
       "         [5.1223e-06, 5.3390e-06, 5.5626e-06,  ..., 4.5598e-13, 3.1772e-13,\n",
       "          1.8918e-13],\n",
       "         [5.6103e-06, 5.8477e-06, 6.0926e-06,  ..., 7.0659e-13, 5.4950e-13,\n",
       "          4.0347e-13],\n",
       "         ...,\n",
       "         [2.3189e-05, 2.4268e-05, 2.5390e-05,  ..., 3.9155e-05, 3.6214e-05,\n",
       "          3.3479e-05],\n",
       "         [2.1349e-05, 2.2344e-05, 2.3378e-05,  ..., 3.7316e-05, 3.4513e-05,\n",
       "          3.1907e-05],\n",
       "         [1.9647e-05, 2.0564e-05, 2.1518e-05,  ..., 3.5549e-05, 3.2878e-05,\n",
       "          3.0396e-05]]),\n",
       " 'metrics': {'KLD': 12.04793930053711,\n",
       "  'SIM': 0.0006013938691467047,\n",
       "  'NSS': -0.6110530495643616}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "action = sample_info[\"action\"]\n",
    "object_name = sample_info[\"object\"]\n",
    "\n",
    "image_path = get_actual_path(sample_info[\"image_path\"])\n",
    "gt_path = get_gt_path(image_path)    \n",
    "print(f\"Action : {action}, Object : {object_name} image_name : {image_path.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "# Process the image\n",
    "prompt = my_prompt.process_image_ego_prompt(action, object_name)\n",
    "        \n",
    "results = model.process_image_ego(image_path, prompt, gt_path, action)\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f36f7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : push, Object : bicycle image_name : bicycle_002432.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    You are given two images:\\n    1. An **egocentric** image where you must select keypoints.\\n    2. An **exocentric** reference image showing how the action 'push' is typically performed on the 'bicycle'.\\n\\n    üéØ Your task:\\n    Identify several **precise keypoints** in the image that are essential for performing the action 'push' on the object 'bicycle'.\\n    and rating the importance of that point\\n\\n    üîç Use the exocentric image to:\\n    - Understand typical interaction patterns\\n    - Identify functionally important parts (e.g., contact or force areas)\\n\\n    üìå Guidelines:\\n    - Only return **single-point** coordinates and prediction score in the format [x, y, prediction_score]\\n    - Do **not** return bounding boxes or regions\\n    - All points must lie **within** the 'bicycle'\\n    - Avoid placing multiple points too close together\\n    - If there are more than one 'bicycle', give me point from each 'bicycle'\\n\\n    ‚õî Do NOT:\\n    - Include text, labels, bounding boxes, or extra formatting\\n\\n    ‚úÖ Output format (strict):\\n    [\\n    [x1, y1, prediction_score],\\n    [x2, y2, prediction_score],\\n    [x3, y3, prediction_score]\\n    ]\\n    \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "action = sample_info[\"action\"]\n",
    "object_name = sample_info[\"object\"]\n",
    "\n",
    "image_path = get_actual_path(sample_info[\"image_path\"])\n",
    "gt_path = get_gt_path(image_path)    \n",
    "print(f\"Action : {action}, Object : {object_name} image_name : {image_path.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "# Process the image\n",
    "prompt = my_prompt.process_image_exo_prompt_w_pred(action, object_name)\n",
    "prompt    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e949c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exo file name : push_bicycle_010074.jpg / exo_path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final points :[[340, 205], [270, 290], [160, 340]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text_result': '[\\n    [340, 205, 0.8],  # Handlebar area for pushing\\n    [270, 290, 0.7],  # Frame near the seat for pushing\\n    [160, 340, 0.6]   # Rear wheel area for pushing\\n]',\n",
       " 'dots': [[340, 205], [270, 290], [160, 340]],\n",
       " 'dot_image_path': '/root/qwen_AG_new/dot_images/with_exo/bicycle_002432_push_exo_push_bicycle_010074.jpg',\n",
       " 'dot_only_image_path': '/root/qwen_AG_new/dot_images/dots_only/bicycle_002432_push_dots_exo.jpg',\n",
       " 'heatmap_image_path': '/root/qwen_AG_new/dot_images/heatmaps/bicycle_002432_push_heatmap_exo_reference_push_bicycle_010074.jpg',\n",
       " 'heatmap_tensor': tensor([[0.0000e+00, 1.1686e-14, 2.4192e-14,  ..., 1.3084e-12, 1.1373e-12,\n",
       "          9.8563e-13],\n",
       "         [2.3882e-14, 3.7280e-14, 5.1614e-14,  ..., 1.4390e-12, 1.2527e-12,\n",
       "          1.0875e-12],\n",
       "         [5.1258e-14, 6.6616e-14, 8.3043e-14,  ..., 1.5805e-12, 1.3776e-12,\n",
       "          1.1978e-12],\n",
       "         ...,\n",
       "         [1.0162e-03, 1.0860e-03, 1.1601e-03,  ..., 3.2173e-13, 2.6520e-13,\n",
       "          2.1516e-13],\n",
       "         [9.8150e-04, 1.0489e-03, 1.1205e-03,  ..., 2.8029e-13, 2.2862e-13,\n",
       "          1.8287e-13],\n",
       "         [9.4755e-04, 1.0126e-03, 1.0817e-03,  ..., 2.4227e-13, 1.9504e-13,\n",
       "          1.5324e-13]]),\n",
       " 'metrics': {'KLD': 6.8276214599609375,\n",
       "  'SIM': 0.032363295555114746,\n",
       "  'NSS': -0.449908584356308}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exo_path = \"/root/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_010074.jpg\"\n",
    "results = model.process_image_exo(image_path, prompt,gt_path, exo_path, action)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4046db17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    [340, 205, 0.8],  # Handlebar area for pushing\n",
      "    [270, 290, 0.7],  # Frame near the seat for pushing\n",
      "    [160, 340, 0.6]   # Rear wheel area for pushing\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(results['text_result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
