{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccef783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen25/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "import my_prompt5 as my_prompt\n",
    "from file_managing import (\n",
    "    load_selected_samples,\n",
    "    get_actual_path,\n",
    "    get_gt_path,\n",
    ")\n",
    "from config import AGD20K_PATH, model_name\n",
    "from VLM_model_dot import QwenVLModel, MetricsTracker\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"PYTORCH_ENABLE_SDPA\"] = \"1\"\n",
    "\n",
    "missing_gt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3338eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def affordance_grounding(model, action, object_name, image_path, gt_path, exo_path=None,  failed_heatmap_path=None, validation_reason=None):\n",
    "    \"\"\"\n",
    "    Process each image using Qwen VL model\n",
    "    \"\"\"\n",
    "    print(f\"Processing image: Action: {action}, Object: {object_name}, Image path: {image_path}, GT path: {gt_path}, Image exists: {os.path.exists(image_path)}, GT exists: {os.path.exists(gt_path)}\")\n",
    "    \n",
    "\n",
    "    if exo_path is None:\n",
    "        prompt = my_prompt.process_image_ego_prompt(action, object_name)\n",
    "               \n",
    "        results = model.process_image_ego(image_path, prompt, gt_path, action)\n",
    "\n",
    "        \n",
    "    else:\n",
    "\n",
    "        prompt = my_prompt.process_image_exo_prompt(action, object_name)\n",
    "        results = model.process_image_exo(image_path, prompt, gt_path, exo_path, action)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8778ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: cuda\n",
      "ü§ñ Qwen/Qwen2.5-VL-3B-Instruct Î™®Îç∏ Î°úÎî©Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Î™®Îç∏ Î°úÎî© ÏôÑÎ£å!\n",
      "Processing 123 samples...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "    # Initialize Qwen VL model\n",
    "    model = QwenVLModel(model_name = model_name)\n",
    "    metrics_tracker_ego = MetricsTracker(name=\"only_ego\")\n",
    "    metrics_tracker_exo_best = MetricsTracker(name=\"with_exo_best\")\n",
    "\n",
    "    json_path = os.path.join(\"selected_samples.json\")\n",
    "    data = load_selected_samples(json_path)\n",
    "\n",
    "    # Get total number of samples\n",
    "    total_samples = len(data['selected_samples'])\n",
    "    \n",
    "    # Process each sample\n",
    "    print(f\"Processing {total_samples} samples...\")\n",
    "    print(\"=\" * 50)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d87523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump_skis {'action': 'jump', 'object': 'skis', 'image_path': '${AGD20K_PATH}/Seen/testset/egocentric/jump/skis/skis_002829.jpg'}\n"
     ]
    }
   ],
   "source": [
    "for pair_key, sample_info in data[\"selected_samples\"].items():\n",
    "    if( sample_info['object'] =='skis') and (  sample_info['action'] =='jump'):\n",
    "        print(pair_key, sample_info )\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c93e07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n        You are given an image showing a 'skis' involved in the action 'jump'.\\n\\n        üéØ Your task:\\n        Identify several **precise keypoints** in the image that are essential for performing the action 'jump' on the object 'skis'.\\n        and rating the importance of that point\\n\\n        ‚ö†Ô∏è Important Instructions:\\n        - Only return **single-point** coordinates and prediction score in the format [x, y, prediction_score]\\n        - Do **not** return bounding boxes or regions\\n        - All points must lie **within** the 'skis'\\n        - Avoid placing multiple points too close together\\n        - If there are more than one 'skis', give me point from each 'skis'\\n        - ‚ùå Do **not** include any text, comments, or labels\\n\\n        ‚úÖ Output format (strict):\\n        [\\n        [x1, y1,prediction_score],\\n        [x2, y2,prediction_score],\\n        [x3, y3,prediction_score]\\n        ]\\n        \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = sample_info[\"action\"]\n",
    "object_name = sample_info[\"object\"]\n",
    "my_prompt.process_image_ego_prompt_w_pred(action, object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "719e58bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7efccd3353d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(int,[1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89971dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : jump, Object : skis image_name : skis_002829.jpg\n",
      "qwen ego Results!! : [\n",
      "    [105, 14, 210, 1406, 0.9],\n",
      "    [340, 14, 455, 1406, 0.9]\n",
      "]\n",
      "No dot coordinates found, trying to parse as bounding boxes...\n",
      "text : [\n",
      "    [105, 14, 210, 1406, 0.9],\n",
      "    [340, 14, 455, 1406, 0.9]\n",
      "]\n",
      "final points :[]\n",
      "parsed dots!!! : []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text_result': '[\\n    [105, 14, 210, 1406, 0.9],\\n    [340, 14, 455, 1406, 0.9]\\n]',\n",
       " 'dots': [],\n",
       " 'dot_image_path': '/home/bongo/porter_notebook/research/new_qwen_AG/dot_images/only_ego/skis_002829_jump.jpg',\n",
       " 'dot_only_image_path': '/home/bongo/porter_notebook/research/new_qwen_AG/dot_images/dots_only/skis_002829_jump_dots.jpg',\n",
       " 'heatmap_image_path': '/home/bongo/porter_notebook/research/new_qwen_AG/dot_images/heatmaps/skis_002829_jump_heatmap.jpg',\n",
       " 'heatmap_tensor': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'metrics': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "action = sample_info[\"action\"]\n",
    "object_name = sample_info[\"object\"]\n",
    "\n",
    "image_path = get_actual_path(sample_info[\"image_path\"])\n",
    "gt_path = get_gt_path(image_path)    \n",
    "print(f\"Action : {action}, Object : {object_name} image_name : {image_path.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "# Process the image\n",
    "prompt = my_prompt.process_image_ego_prompt_w_pred(action, object_name)\n",
    "        \n",
    "results = model.process_image_ego(image_path, prompt, gt_path, action)\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db024ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : jump, Object : skis image_name : skis_002829.jpg\n",
      "Processing image: Action: jump, Object: skis, Image path: /home/DATA/AGD20K/Seen/testset/egocentric/jump/skis/skis_002829.jpg, GT path: /home/DATA/AGD20K/Seen/testset/GT/jump/skis/skis_002829.png, Image exists: True, GT exists: True\n",
      "qwen ego Results!! : [\n",
      "    [105, 14], \n",
      "    [105, 1368], \n",
      "    [347, 14], \n",
      "    [347, 1368]\n",
      "]\n",
      "parsed dots!!! : [[105, 14], [105, 1368], [347, 14], [347, 1368]]\n",
      "\n",
      "==================================================\n",
      "Metrics for only_ego skis_002829.jpg:\n",
      " only_ego Current - KLD: 11.5107 | SIM: 0.0000 | NSS: -0.6241\n",
      "\n",
      "Cumulative only_ego  Averages over 1 samples:\n",
      "Average - KLD: 11.5107 | SIM: 0.0000 | NSS: -0.6241\n",
      "==================================================\n",
      "\n",
      "Processing image: Action: jump, Object: skis, Image path: /home/DATA/AGD20K/Seen/testset/egocentric/jump/skis/skis_002829.jpg, GT path: /home/DATA/AGD20K/Seen/testset/GT/jump/skis/skis_002829.png, Image exists: True, GT exists: True\n",
      "exo file name : dogs.jpg / exo_path\n",
      "\n",
      "==================================================\n",
      "Metrics for with_exo_best skis_002829.jpg:\n",
      " with_exo_best Current - KLD: 11.5114 | SIM: 0.0000 | NSS: -0.3291\n",
      "\n",
      "Cumulative with_exo_best  Averages over 1 samples:\n",
      "Average - KLD: 11.5114 | SIM: 0.0000 | NSS: -0.3291\n",
      "==================================================\n",
      "\n",
      "*** End   ******************************************************************************************************************************************************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action = sample_info[\"action\"]\n",
    "object_name = sample_info[\"object\"]\n",
    "\n",
    "image_path = get_actual_path(sample_info[\"image_path\"])\n",
    "gt_path = get_gt_path(image_path)    \n",
    "print(f\"Action : {action}, Object : {object_name} image_name : {image_path.split('/')[-1]}\")\n",
    "exo_best_path = \"dogs.jpg\"\n",
    "if  (exo_best_path is None):\n",
    "    print(f\"NO SEEN DATA SET : {action}/{object_name}\")\n",
    "\n",
    "# Process the image\n",
    "results_ego = affordance_grounding(model, action, object_name, image_path, gt_path)\n",
    "metrics_ego = results_ego['metrics']\n",
    "if metrics_ego:\n",
    "    # Update and print metrics\n",
    "    metrics_tracker_ego.update(metrics_ego)\n",
    "    metrics_tracker_ego.print_metrics(metrics_ego, image_path.split('/')[-1])\n",
    "    \n",
    "# with exo random\n",
    "results_exo_best = affordance_grounding(model, action, object_name, image_path, gt_path, exo_best_path)     \n",
    "metrics_exo_best = results_exo_best['metrics']\n",
    "\n",
    "if metrics_exo_best:\n",
    "    metrics_tracker_exo_best.update(metrics_exo_best)\n",
    "    metrics_tracker_exo_best.print_metrics(metrics_exo_best, image_path.split('/')[-1])\n",
    "    \n",
    "    \n",
    "# Count missing GT files\n",
    "if not os.path.exists(gt_path):\n",
    "    missing_gt += 1\n",
    "\n",
    "print(\"*** End  \", \"*\"*150)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37584927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
